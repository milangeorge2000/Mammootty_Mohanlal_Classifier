{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "tinkerhub'.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89e1731862984d47b018fcd170f2e774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5a3f5382fd44f87acf9fef58381875d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f06149cfb14425ba29e011d4f46677e",
              "IPY_MODEL_5c6104d9e02a4d6fb78155b7d72681c2"
            ]
          }
        },
        "c5a3f5382fd44f87acf9fef58381875d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f06149cfb14425ba29e011d4f46677e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc08093450bd421ca9fb8f5e61d96619",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 111898327,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 111898327,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5bed47c58e54edcb547f6e27d03a128"
          }
        },
        "5c6104d9e02a4d6fb78155b7d72681c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e34e393815b4425d9d80b9812971fd2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 107M/107M [00:01&lt;00:00, 67.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_665ced90d7f84c77968d93cf052d9dc4"
          }
        },
        "cc08093450bd421ca9fb8f5e61d96619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5bed47c58e54edcb547f6e27d03a128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e34e393815b4425d9d80b9812971fd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "665ced90d7f84c77968d93cf052d9dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II0-BLcAQDTJ",
        "outputId": "0bc92f82-b8f5-406a-94cb-da3f3100b59c"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        " \n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/My Drive/tinkerhub'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/tinkerhub\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIpQfNVoSQtW",
        "outputId": "c21343b5-56a4-4722-92cd-477651b2541b"
      },
      "source": [
        "!pip install facenet_pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting facenet_pytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e8/5ea742737665ba9396a8a2be3d2e2b49a13804b56a7e7bb101e8731ade8f/facenet_pytorch-2.5.2-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.9.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision->facenet_pytorch) (3.7.4.3)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dps6WvsSNwx"
      },
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTFOtVQnQDTK"
      },
      "source": [
        "\n",
        "mtcnn = MTCNN(image_size=240, margin=0, min_face_size=20) # initializing mtcnn for face detection\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval() # initializing resnet for face img to embeding conversion\n",
        "\n",
        "dataset=datasets.ImageFolder('train') # photos folder path \n",
        "idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n",
        "\n",
        "def collate_fn(x):\n",
        "    return x[0]\n",
        "\n",
        "loader = DataLoader(dataset, collate_fn=collate_fn)\n",
        "\n",
        "face_list = [] # list of cropped faces from photos folder\n",
        "name_list = [] # list of names corrospoing to cropped photos\n",
        "embedding_list = [] # list of embeding matrix after conversion from cropped faces to embedding matrix using resnet\n",
        "\n",
        "for img, idx in loader:\n",
        "    face, prob = mtcnn(img, return_prob=True) \n",
        "    if face is not None and prob>0.90: # if face detected and porbability > 90%\n",
        "        emb = resnet(face.unsqueeze(0)) # passing cropped face into resnet model to get embedding matrix\n",
        "        embedding_list.append(emb.detach()) # resulten embedding matrix is stored in a list\n",
        "        name_list.append(idx_to_class[idx]) # names are stored in a list\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbMnwffnQDTL"
      },
      "source": [
        "data = [embedding_list, name_list]\n",
        "torch.save(data, 'data2.pt') # saving data.pt file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "89e1731862984d47b018fcd170f2e774",
            "c5a3f5382fd44f87acf9fef58381875d",
            "1f06149cfb14425ba29e011d4f46677e",
            "5c6104d9e02a4d6fb78155b7d72681c2",
            "cc08093450bd421ca9fb8f5e61d96619",
            "c5bed47c58e54edcb547f6e27d03a128",
            "e34e393815b4425d9d80b9812971fd2e",
            "665ced90d7f84c77968d93cf052d9dc4"
          ]
        },
        "id": "oBuvRHu0OtFr",
        "outputId": "e6755b44-345b-4886-b5dd-1062e35324c4"
      },
      "source": [
        "mtcnn = MTCNN(image_size=240, margin=0, min_face_size=20) # initializing mtcnn for face detection\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval() # initializing resnet for face img to embeding conversion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e1731862984d47b018fcd170f2e774",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=111898327.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsXeEB88QDTM"
      },
      "source": [
        "### Matching face id of the given photo with available data from data2.pt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO-5EHuxQDTM",
        "outputId": "f59556e0-fe2d-4b9c-e69c-209181fc0478"
      },
      "source": [
        "\n",
        "def face_match(img_path, data_path): # img_path= location of photo, data_path= location of data.pt \n",
        "    # getting embedding matrix of the given img\n",
        "    img = Image.open(img_path)\n",
        "    face, prob = mtcnn(img, return_prob=True) # returns cropped face and probability\n",
        "    emb = resnet(face.unsqueeze(0)).detach() # detech is to make required gradient false\n",
        "    print(prob)\n",
        "    saved_data = torch.load('data2.pt') # loading data.pt file\n",
        "    embedding_list = saved_data[0] # getting embedding data\n",
        "    name_list = saved_data[1] # getting list of names\n",
        "    dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
        "    \n",
        "    for idx, emb_db in enumerate(embedding_list):\n",
        "        dist = torch.dist(emb, emb_db).item()\n",
        "        dist_list.append(dist)\n",
        "        \n",
        "    idx_min = dist_list.index(min(dist_list))\n",
        "    return (name_list[idx_min], min(dist_list))\n",
        "\n",
        "\n",
        "result = face_match('download (16).jpg', 'data2.pt')\n",
        "\n",
        "print('Face matched with: ',result[0], 'With distance: ',result[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9997813\n",
            "Face matched with:  mammootty With distance:  0.9119095802307129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkkPENgXXhbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29c7936-c817-4cdd-c6e8-9b461c2743e7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/tinkerhub\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ6kxJATl3J2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}